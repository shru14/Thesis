# Thesis
Master's thesis code for the course Data science for Public policy

Data folder: https://drive.google.com/drive/folders/1Oig9P4DYwXggJQEAI_JwCv1RH-ddEMbr?usp=sharing

Title 

Code of Justice: A Sector-Specific Quantitative Analysis of Regulatory Gaps in the U.S. Federal Courts for AI Governance

Name of the thesis supervisor

Dr. William Lowe

Name of the practice partner

Indian Society of AI and Law


Student’s name, study programme and year of graduation

Shruti Kakade

Matriculation Number 

233146

Got accepted at the Data for Policy Conference 2025. 
https://dataforpolicy.org/data-for-policy-2025-europe/

Executive Summary:
The rapid expansion of artificial intelligence (AI) across major U.S. sectors—including 
healthcare, finance, and technology—has outpaced the ability of existing legal frameworks 
to provide clear, consistent regulatory guidance. The U.S. regulatory environment for AI 
remains highly fragmented, shaped by a patchwork of federal agency guidelines, state laws, 
and judicial interpretation rather than a unified policy framework. This has led to 
sector-specific gaps and inconsistencies, especially as courts increasingly address novel legal 
questions arising from AI deployment. This paper introduces a quantitative, data-driven 
methodology to systematically identify and measure regulatory gaps in AI governance by 
analyzing U.S. federal court opinions from 2010 to 2025. Using the Free Law Project’s 
CourtListener API and natural language processing, we assembled a comprehensive dataset 
of judicial opinions relevant to AI. Legal citations, sectoral, and temporal metadata were 
extracted from each opinion. 
To capture regulatory ambiguity, we introduce the Regulatory Gap Index (RGI), which 
synthesizes citation density, citation diversity, lexical complexity, and hedging frequency. The 
Regulatory Gap Percentage (RGP) quantifies the share of cases in a sector that exhibit 
systemic indicators of regulatory strain or failure. High regulatory failure cases are identified 
through a composite of structural signals, including low citation grounding, high RGI, and 
unresolved judicial outcomes. The RGP reflects the proportion of such cases within a sector, 
enabling comparative measurement of regulatory adequacy and strain across sectors, 
courts, and years. To further investigate determinants and consequences of regulatory 
ambiguity, causal inference models are applied to analyze how citations, court circuit, and 
judgment outcome relate to regulatory failure, and to estimate the effect of regulatory strain 
on plaintiff success and case resolution. 
By leveraging quantitative analysis to bridge technological innovation, legal interpretation, 
and policy formulation, this study offers actionable, data-driven insights for policymakers, 
legal scholars, and AI developers. The findings underscore the need for sector-specific, 
evidence-based approaches to AI governance and highlight the importance of consistent, 
transparent metrics in guiding judicial decision-making. Ultimately, this research provides a 
replicable, empirically grounded foundation for developing more effective regulatory 
strategies and contributes a robust framework for future research and policy development in 
AI governance.

